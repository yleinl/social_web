{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reddit Data Collection Script for Candidate Sentiment Analysis\n",
    "\n",
    "This Python script uses the `praw` library to collect comments related to specific candidates from the Reddit subreddit `r/politics`. The collected data includes metadata such as comment text, author, timestamp, and engagement metrics, and it saves the data into a CSV file.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. **Reddit API Configuration**:\n",
    "   - The script authenticates using `praw`, with a `client_id`, `client_secret`, and a custom `user_agent`.\n",
    "   - Replace the placeholders with your own Reddit API credentials to run the script.\n",
    "\n",
    "2. **Candidate-Specific Comment Collection**:\n",
    "   - The `fetch_candidate_comments` function collects comments for a specified candidate and party affiliation.\n",
    "   - Metadata such as comment ID, user handle, timestamp, comment text, upvotes, number of replies, and awards count is extracted for each comment.\n",
    "\n",
    "3. **Candidate and Party Information**:\n",
    "   - A dictionary `candidates_info` maps candidates to their respective political parties.\n",
    "   - The script iterates through this dictionary to fetch data for all listed candidates.\n",
    "\n",
    "4. **Saving Data**:\n",
    "   - Collected data from all candidates is combined into a single Pandas DataFrame.\n",
    "   - The DataFrame is exported to a CSV file named `reddit_candidate_comments_praw.csv`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4d5489257e39c58"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for Kamala Harris (Democratic)...\n",
      "Fetching comments for Donald Trump (Republican)...\n",
      "Fetching comments for Jill Stein (Green)...\n",
      "Fetching comments for Robert Kennedy (Independent)...\n",
      "Fetching comments for Chase Oliver (Libertarian)...\n",
      "  comment_id    user_handle           timestamp  \\\n",
      "0    lviwuzp  AutoModerator 2024-11-05 15:19:02   \n",
      "1    lvj632v      Gymrat777 2024-11-05 16:09:12   \n",
      "2    lvj74ic       martapap 2024-11-05 16:14:33   \n",
      "3    lvix1ez    Blackwardz3 2024-11-05 15:20:03   \n",
      "4    lvjadkj     middlebird 2024-11-05 16:31:05   \n",
      "\n",
      "                                        comment_text      candidate  \\\n",
      "0  \\nAs a reminder, this subreddit [is for civil ...  Kamala Harris   \n",
      "1  There's another poll going on right now - it's...  Kamala Harris   \n",
      "2  Just actually vote people. Don't assume anythi...  Kamala Harris   \n",
      "3  Nice. Don‚Äôt get complacent though. Vote if you...  Kamala Harris   \n",
      "4  Dear college age redditors.\\n\\nI know you have...  Kamala Harris   \n",
      "\n",
      "        party  upvotes  replies  awards  \n",
      "0  Democratic        1        0       0  \n",
      "1  Democratic    19001        7       0  \n",
      "2  Democratic     6285        4       0  \n",
      "3  Democratic    15354        5       0  \n",
      "4  Democratic     7819       14       0  \n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"zC96I9IB346LY9OD5RSrmg\",       # Replace with your Client ID\n",
    "    client_secret=\"iNJWZGyfD17UIAs4KxCyoS8xa4_eSQ\", # Replace with your Secret Key\n",
    "    user_agent=\"ytlei2\",  # Custom user agent\n",
    ")\n",
    "\n",
    "# Fetch comments for a specific candidate\n",
    "def fetch_candidate_comments(candidate, party, num_comments=10000):\n",
    "    comments_data = []\n",
    "    subreddit = reddit.subreddit(\"politics\")\n",
    "    comment_count = 0  # Track the number of comments fetched\n",
    "\n",
    "    # Search posts related to the candidate\n",
    "    for submission in subreddit.search(candidate, limit=num_comments):\n",
    "        submission.comments.replace_more(limit=0)  # Flatten the comment tree\n",
    "        for comment in submission.comments.list():\n",
    "            if comment_count >= num_comments:  # Stop if we've collected enough comments\n",
    "                break\n",
    "            comments_data.append({\n",
    "                \"comment_id\": comment.id,\n",
    "                \"user_handle\": comment.author.name if comment.author else \"deleted\",\n",
    "                \"timestamp\": datetime.fromtimestamp(comment.created_utc),\n",
    "                \"comment_text\": comment.body,\n",
    "                \"candidate\": candidate,\n",
    "                \"party\": party,\n",
    "                \"upvotes\": comment.score,\n",
    "                \"replies\": len(comment.replies) if hasattr(comment, \"replies\") else 0,\n",
    "                \"awards\": comment.total_awards_received  # Awards count\n",
    "            })\n",
    "            comment_count += 1\n",
    "        if comment_count >= num_comments:  # Break out of outer loop if limit reached\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(comments_data)\n",
    "\n",
    "# Define candidates and their parties\n",
    "candidates_info = {\n",
    "    \"Kamala Harris\": \"Democratic\",\n",
    "    \"Donald Trump\": \"Republican\",\n",
    "    \"Jill Stein\": \"Green\",\n",
    "    \"Robert Kennedy\": \"Independent\",\n",
    "    \"Chase Oliver\": \"Libertarian\"\n",
    "}\n",
    "\n",
    "# Fetch data for each candidate\n",
    "all_comments = []\n",
    "for candidate, party in candidates_info.items():\n",
    "    print(f\"Fetching comments for {candidate} ({party})...\")\n",
    "    candidate_comments = fetch_candidate_comments(candidate, party, num_comments=1000)\n",
    "    all_comments.append(candidate_comments)\n",
    "\n",
    "# Combine all candidates' comments into a single DataFrame\n",
    "comments_df = pd.concat(all_comments, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "comments_df.to_csv(\"reddit_candidate_comments_praw.csv\", index=False)\n",
    "\n",
    "print(comments_df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957684c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Filtering High-Quality Reddit Comments for Candidate Analysis\n",
    "\n",
    "This segment of the script refines the collected Reddit comments to retain only high-quality, relevant entries. The goal is to remove bot-generated comments, ensure single-candidate relevance, and select the top comments based on community engagement (upvotes).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee5318d86b2d63b8"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebb6d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     comment_id    user_handle           timestamp  \\\n",
      "4415    l5tfyku      neuroid99 2024-05-27 02:22:31   \n",
      "4417    l5t76l5  atomsmasher66 2024-05-27 01:16:06   \n",
      "4480    l5u3iym    hatrickstar 2024-05-27 05:23:36   \n",
      "4418    l5t7ooz        deleted 2024-05-27 01:19:53   \n",
      "4488    l5t7gnp        DJErikD 2024-05-27 01:18:14   \n",
      "\n",
      "                                           comment_text     candidate  \\\n",
      "4415  While I think the Libertarian party is full of...  Chase Oliver   \n",
      "4417         But his brain worm is still in the running  Chase Oliver   \n",
      "4480  True libertarian are loons but they truly aren...  Chase Oliver   \n",
      "4418                                          [deleted]  Chase Oliver   \n",
      "4488                               üêõ BRAIN WORM 2024. üêõ  Chase Oliver   \n",
      "\n",
      "            party  upvotes  replies  awards  \n",
      "4415  Libertarian     2089        7       0  \n",
      "4417  Libertarian      964       11       0  \n",
      "4480  Libertarian      693       19       0  \n",
      "4418  Libertarian      558        7       0  \n",
      "4488  Libertarian      381        8       0  \n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def is_bot_comment(user_handle, comment_text):\n",
    "    bot_indicators = ['AutoModerator', 'bot', 'moderator']\n",
    "    if any(indicator.lower() in (user_handle or '').lower() for indicator in bot_indicators):\n",
    "        return True\n",
    "    if \"I am a bot\" in comment_text or \"this action was performed automatically\" in comment_text:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_relevant_comment(comment_text, keywords):\n",
    "    blob = TextBlob(comment_text)\n",
    "    return any(keyword.lower() in blob.words.lower() for keyword in keywords)\n",
    "\n",
    "def filter_high_quality_comments(df, candidates, short, top_n=100):\n",
    "    def contains_single_candidate(comment_text, candidates):\n",
    "        count = sum(candidate.lower() in comment_text.lower() for candidate in candidates)\n",
    "        return count < 2\n",
    "\n",
    "    df = df[~df.apply(lambda row: is_bot_comment(row['user_handle'], row['comment_text']), axis=1)]\n",
    "\n",
    "    df = df[df['comment_text'].apply(lambda x: contains_single_candidate(x, candidates))]\n",
    "    df = df[df['comment_text'].apply(lambda x: contains_single_candidate(x, short))]\n",
    "\n",
    "    df = df.sort_values(['candidate', 'upvotes'], ascending=[True, False])\n",
    "    filtered_df = df.groupby('candidate').head(top_n)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "candidates_list = [\"Kamala Harris\", \"Donald Trump\", \"Jill Stein\", \"Robert Kennedy\", \"Chase Oliver\"]\n",
    "candidates_short_list = [\"Harris\", \"Trump\", \"Stein\", \"Kennedy\", \"Oliver\"]\n",
    "\n",
    "filtered_comments_df = filter_high_quality_comments(comments_df, candidates=candidates_list, short=candidates_short_list, top_n=100)\n",
    "\n",
    "filtered_comments_df.to_csv(\"reddit.csv\", index=False)\n",
    "\n",
    "print(filtered_comments_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
